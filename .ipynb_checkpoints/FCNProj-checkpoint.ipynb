{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "file = [\"www.google.com\",\n",
    "        \"www.facebook.com\",\n",
    "        \"www.youtube.com\",\n",
    "        \"www.baidu.com\",\n",
    "        \"www.yahoo.com\",\n",
    "        \"www.amazon.com\",\n",
    "        \"www.wikipedia.org\",\n",
    "        \"www.qq.com\",\n",
    "        \"www.taobao.com\",\n",
    "        \"www.twitter.com\",\n",
    "        \"www.google.co.in\",\n",
    "        \"www.live.com\",\n",
    "        \"www.sina.com.cn\",\n",
    "        \"www.linkedin.com\",\n",
    "        \"www.weibo.com\",\n",
    "        \"www.yahoo.co.jp\",\n",
    "        \"www.google.co.jp\",\n",
    "        \"www.google.ca\",\n",
    "        \"www.ok.ru\",\n",
    "        \"www.adcash.com\",\n",
    "        \"www.google.com.mx\",\n",
    "        \"www.diply.com\",\n",
    "        \"www.tianya.cn\",\n",
    "        \"www.google.com.hk\",\n",
    "        \"www.pornhub.com\",\n",
    "        \"www.alibaba.com\",\n",
    "        \"www.rakuten.co.jp\",\n",
    "        \"www.naver.com\",\n",
    "        \"www.amazon.co.uk\",\n",
    "        \"www.google.com.tr\",\n",
    "        \"www.adobe.com\",\n",
    "        \"www.xinhuanet.com\",\n",
    "        \"www.gmail.com\",\n",
    "        \"www.outbrain.com\",\n",
    "        \"www.xhamster.com\",\n",
    "        \"www.detail.tmall.com\",\n",
    "        \"www.soso.com\",\n",
    "        \"www.google.co.id\",\n",
    "        \"www.ebay.de\",\n",
    "        \"www.kat.cr\",\n",
    "        \"www.people.com.cn\",\n",
    "        \"www.google.pl\",\n",
    "        \"www.jd.com\",\n",
    "        \"www.cntv.cn\",\n",
    "        \"www.gmw.cn\",\n",
    "        \"www.google.com.au\",\n",
    "        \"www.go.com\",\n",
    "        \"www.nicovideo.jp\",\n",
    "        \"www.flipkart.com\",\n",
    "        \"www.cnn.com\",\n",
    "        \"www.dailymotion.com\",\n",
    "        \"www.bbc.co.uk\",\n",
    "        \"www.booking.com\",\n",
    "        \"www.github.com\",\n",
    "        \"www.googleusercontent.com\",\n",
    "        \"www.pixnet.net\",\n",
    "        \"www.dropbox.com\",\n",
    "        \"www.wikia.com\",\n",
    "        \"www.163.com\",\n",
    "        \"www.chinadaily.com.cn\"\n",
    "        ]\n",
    "\n",
    "category = {}\n",
    "category[\"www.google.com\"] = 0\n",
    "category[\"www.facebook.com\"] = 1\n",
    "category[\"www.youtube.com\"] = 2\n",
    "category[\"www.baidu.com\"] = 0\n",
    "category[\"www.yahoo.com\"] = 1\n",
    "category[\"www.amazon.com\"] = 2\n",
    "category[\"www.wikipedia.org\"] = 3\n",
    "category[\"www.twitter.com\"] = 1\n",
    "category[\"www.google.co.in\"] = 0\n",
    "category[\"www.linkedin.com\"] = 1\n",
    "category[\"www.yahoo.co.jp\"] = 1\n",
    "category[\"www.google.co.jp\"] = 0\n",
    "category[\"www.google.ca\"] = 0\n",
    "category[\"www.qq.com\"] = 2\n",
    "category[\"www.taobao.com\"] = 2\n",
    "category[\"www.live.com\"] = 1\n",
    "category[\"www.google.com.mx\"] = 0\n",
    "category[\"www.google.com.hk\"] = 0\n",
    "category[\"www.pornhub.com\"] = 2\n",
    "category[\"www.alibaba.com\"] = 2\n",
    "category[\"www.amazon.co.uk\"] = 2\n",
    "category[\"www.google.com.tr\"] = 0\n",
    "category[\"www.adobe.com\"] = 0\n",
    "category[\"www.gmail.com\"] = 0\n",
    "category[\"www.xhamster.com\"] = 2\n",
    "category[\"www.ebay.de\"] = 2\n",
    "category[\"www.google.pl\"] = 0\n",
    "category[\"www.google.com.au\"] = 0\n",
    "category[\"www.dailymotion.com\"] = 2\n",
    "category[\"www.bbc.co.uk\"] = 2\n",
    "category[\"www.google.co.id\"] = 0\n",
    "category[\"www.flipkart.com\"] = 2\n",
    "category[\"www.cnn.com\"] = 2\n",
    "category[\"www.booking.com\"] = 2\n",
    "category[\"www.github.com\"] = 0\n",
    "category[\"www.dropbox.com\"] = 0\n",
    "category[\"www.people.com.cn\"] = 2\n",
    "category[\"www.nicovideo.jp\"] = 2\n",
    "category[\"www.googleusercontent.com\"] = 0\n",
    "category[\"www.weibo.com\"] = 2\n",
    "category[\"www.sina.com.cn\"] = 2\n",
    "category[\"www.adcash.com\"] = 0\n",
    "category[\"www.ok.ru\"] = 2\n",
    "category[\"www.diply.com\"] = 2\n",
    "category[\"www.tianya.cn\"] = 2\n",
    "category[\"www.jd.com\"] = 2\n",
    "category[\"www.cntv.cn\"] = 0\n",
    "category[\"www.go.com\"] = 2\n",
    "category[\"www.naver.com\"] = 0\n",
    "category[\"www.kat.cr\"] = 0\n",
    "category[\"www.soso.com\"] = 0\n",
    "category[\"www.wikia.com\"] = 0\n",
    "category[\"www.163.com\"] = 2\n",
    "category[\"www.gmw.cn\"] = 2\n",
    "category[\"www.pixnet.net\"] = 3\n",
    "category[\"www.outbrain.com\"] = 3\n",
    "category[\"www.xinhuanet.com\"] = 2\n",
    "category[\"www.rakuten.co.jp\"] = 2\n",
    "category[\"www.detail.tmall.com\"] = 0\n",
    "category[\"www.chinadaily.com.cn\"] = 0\n",
    "\n",
    "def find_PLT(filename):\n",
    "    file = open(filename)\n",
    "    list = file.readlines()\n",
    "    mintime = 0\n",
    "    for line in list:\n",
    "        match = re.match('.*requestTime.: ([0-9^.]+)', line)\n",
    "        if match is not None:\n",
    "            mintime = float(match.groups(0)[0])\n",
    "            break\n",
    "    maxtime = 0\n",
    "    for line in list:\n",
    "        match = re.match('.*time.: ([0-9^.]+)',line)\n",
    "        if match is not None:\n",
    "            if float(match.groups(0)[0]) > maxtime:\n",
    "                maxtime = float(match.groups(0)[0])\n",
    "    \n",
    "    return (maxtime - mintime,mintime,maxtime)\n",
    "            \n",
    "def findcount(text, list):\n",
    "    feature = Counter()\n",
    "    for value in list:\n",
    "        feature[value] = len(re.findall('\\.' + value,text))\n",
    "\n",
    "    return feature\n",
    "\n",
    "\n",
    "def findAllPLT(name,count):\n",
    "    list = []\n",
    "    featureList = ['png','gif','css','js']\n",
    "    feature = Counter()\n",
    "    for i in range(count):\n",
    "        filename = name + str(i)  + \".txt\"\n",
    "        text = open(filename).read()\n",
    "        feature += findcount(text,featureList)\n",
    "        (time,min,max) = find_PLT(filename)\n",
    "        list.append(time)\n",
    "    \n",
    "    for key in featureList:\n",
    "        if key in feature:\n",
    "            feature[key] = (feature[key]*1.0)/count\n",
    "        else:\n",
    "            feature[key] = 0\n",
    "        \n",
    "    return feature,list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = \"/Users/Aman/Desktop/Colin/data_all/results/\"\n",
    "def all_file():\n",
    "    dictionary = {}\n",
    "    for website in file:\n",
    "        feature,list = findAllPLT(filepath + website,7)\n",
    "        dictionary[website] = (feature,list)\n",
    "    return dictionary\n",
    "\n",
    "all_val_dict = all_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for website in file:\n",
    "    if website in all_val_dict.keys():\n",
    "        if max(all_val_dict[website][1]) < 8 and min(all_val_dict[website][1])  > 0:\n",
    "            all_val_dict[website][1].sort()\n",
    "            all_val_dict[website][1].reverse()\n",
    "            plt.plot(all_val_dict[website][1],linewidth=2.0)\n",
    "    \n",
    "plt.ylabel('Time in seconds ---->')\n",
    "plt.xlabel('Iterations ---->')\n",
    "plt.xlim(xmin=1)\n",
    "plt.ylim(ymax=8)\n",
    "plt.grid(True)\n",
    "plt.Arrow(5,5,7,7)\n",
    "plt.title(\"PAGELOAD TIME  vs  ITERATION\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pandas.tools.plotting import parallel_coordinates\n",
    "\n",
    "df = pd.DataFrame(columns=('mean','css', 'gif', 'js','png','cat'))\n",
    "i = 0\n",
    "for website in file:\n",
    "    df.loc[i] = [np.mean(all_val_dict[website][1]),all_val_dict[website][0]['css'],all_val_dict[website][0]['gif'],all_val_dict[website][0]['js'],all_val_dict[website][0]['png'],category[website]]\n",
    "    i += 1\n",
    "\n",
    "df.to_csv('data.csv', sep=',')\n",
    "plt.figure()\n",
    "parallel_coordinates(df,'cat',colormap='gist_rainbow')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from scipy import stats as ss\n",
    "\n",
    "def regression(Y,X):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    Y = np.array(ss.zscore(Y)).T\n",
    "    X = np.array([ss.zscore(x) for x in X.T]).T\n",
    "\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(X,Y)\n",
    "    print('Coefficients: \\n', regr.coef_)\n",
    "    print(\"Residual sum of squares: %.2f\"% np.mean((regr.predict(X) - Y) ** 2))\n",
    "    \n",
    "    return regr    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "www.google.com\n",
      "www.facebook.com\n",
      "www.youtube.com\n",
      "www.baidu.com\n",
      "www.yahoo.com\n",
      "www.amazon.com\n",
      "www.wikipedia.org\n",
      "www.qq.com\n",
      "www.taobao.com\n",
      "www.twitter.com\n",
      "www.google.co.in\n",
      "www.live.com\n",
      "www.sina.com.cn\n",
      "www.linkedin.com\n",
      "www.weibo.com\n",
      "www.yahoo.co.jp\n",
      "www.google.co.jp\n",
      "www.google.ca\n",
      "www.ok.ru\n",
      "www.adcash.com\n",
      "www.google.com.mx\n",
      "www.diply.com\n",
      "www.tianya.cn\n",
      "www.google.com.hk\n",
      "www.pornhub.com\n",
      "www.alibaba.com\n",
      "www.rakuten.co.jp\n",
      "www.naver.com\n",
      "www.amazon.co.uk\n",
      "www.google.com.tr\n",
      "www.adobe.com\n",
      "www.xinhuanet.com\n",
      "www.gmail.com\n",
      "www.outbrain.com\n",
      "www.xhamster.com\n",
      "www.soso.com\n",
      "www.google.co.id\n",
      "www.ebay.de\n",
      "www.kat.cr\n",
      "www.people.com.cn\n",
      "www.google.pl\n",
      "www.jd.com\n",
      "www.cntv.cn\n",
      "www.google.com.au\n",
      "www.go.com\n",
      "www.nicovideo.jp\n",
      "www.flipkart.com\n",
      "www.dailymotion.com\n",
      "www.bbc.co.uk\n",
      "www.booking.com\n",
      "www.googleusercontent.com\n",
      "www.pixnet.net\n",
      "www.dropbox.com\n",
      "www.wikia.com\n",
      "www.163.com\n",
      "www.chinadaily.com.cn\n",
      "[2.1132289999986824, 2.024945999999545, 2.995691000000079, 5.240110000000641, 3.5522009999995134, 5.687685999999303, 2.168401000000813, 6.975617000000057, 6.20297600000049, 4.557440999999926, 1.4861350000010134, 1.3221389999998792, 14.220386999999391, 1.8663020000003598, 3.1497500000004948, 7.1314009999996415, 1.5778559999998834, 1.673012999999628, 5.595109999998385, 5.3413119999995615, 2.7290460000003804, 4.3440149999987625, 7.356618000000708, 2.8904290000027686, 8.730604000000312, 5.168990000000122, 0, 3.3258980000009615, 8.834006999999474, 1.6612199999999575, 8.830257999999958, 11.914213000000018, 3.938959999999497, 4.437957000000097, 8.482540000000881, 9.800284999999349, 2.2999129999989236, 7.796431999999186, 9.471535999997286, 10.022063999999773, 2.1201790000013716, 8.278970999999729, 1.3529120000002877, 2.2096419999998034, 5.5666220000002795, 6.339603999997053, 2.442095000000336, 6.437410999999884, 9.577483999999458, 8.515226999999868, 0.8815699999995559, 8.958182000000306, 8.160852999999406, 9.860209000000395, 8.231762000000344, 6.781689999999799]\n",
      "[[0, 0, 3.8, 0], [4.0, 24.0, 8.1, 27.0], [5.0, 30.6, 16.0, 90.3], [1.0, 4.0, 6.0, 27.2], [9.8, 52.4, 4.9, 168.2], [9.4, 117.1, 29.9, 118.4], [0, 0, 7.0, 16.2], [6.7, 3.2, 38.0, 46.4], [4.3, 42.0, 17.1, 157.5], [2.0, 18.8, 20.6, 31.6], [0, 0, 3.2, 0], [0, 0, 4.0, 11.7], [17.4, 3.8, 7.0, 44.6], [0, 0, 0, 8.0], [0, 0, 0, 5.0], [8.8, 5.0, 9.5, 66.6], [0, 0, 4.3, 0], [0, 0, 4.2, 0], [0, 16.4, 6.0, 42.9], [38.0, 163.0, 18.0, 241.4], [0, 0, 3.2, 0], [2.0, 20.0, 10.3, 98.5], [4.0, 8.0, 10.0, 41.5], [0, 0, 4.1, 0], [44.2, 42.4, 10.4, 112.2], [2.8, 94.0, 5.5, 127.2], [108.0, 5.1, 10.3, 137.5], [44.1, 24.0, 14.4, 46.2], [15.0, 76.6, 26.4, 105.9], [0, 0, 4.3, 0], [1.1, 0, 27.5, 125.9], [27.0, 3.6, 24.3, 110.4], [2.0, 14.0, 17.0, 44.5], [2.7, 4.0, 23.0, 67.3], [49.0, 6.0, 26.0, 17.1], [5.0, 3.0, 4.0, 37.5], [0, 0, 3.2, 0], [2.1, 4.0, 5.8, 29.2], [1.0, 11.0, 5.0, 21.0], [21.6, 4.5, 11.7, 47.4], [0, 0, 3.4, 0], [2.4, 2.3, 0.6, 38.6], [0, 4.0, 26.0, 11.3], [0, 0, 4.2, 0], [0, 35.0, 4.0, 35.8], [1.8, 56.7, 35.1, 138.7], [0.2, 4.0, 17.0, 16.6], [5.6, 8.0, 22.5, 94.7], [5.7, 28.8, 17.6, 158.3], [4.1, 28.0, 17.0, 61.7], [0, 0, 2.0, 0], [10.3, 16.0, 57.3, 163.9], [11.7, 50.4, 45.0, 92.8], [6.0, 5.0, 14.4, 84.9], [56.0, 0, 11.4, 45.3], [10.4, 3.6, 3.6, 35.3]]\n"
     ]
    }
   ],
   "source": [
    "def getValueRegr(all_val_dict):\n",
    "    Y = []\n",
    "    X = []\n",
    "    for website in file:\n",
    "        if sum(all_val_dict[website][1]) == 0:\n",
    "#             print \"Empty: \",website\n",
    "            continue\n",
    "        print website\n",
    "        Y.append(all_val_dict[website][1][0])\n",
    "        X.append(all_val_dict[website][0].values())\n",
    "    \n",
    "    return (Y,X)\n",
    "\n",
    "Y,X = getValueRegr(all_val_dict)\n",
    "print Y\n",
    "print X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coefficients: \\n', array([-0.02382767, -0.25574412,  0.20603117,  0.46287093]))\n",
      "Residual sum of squares: 0.78\n",
      "[ 0.18115328]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Aman/anaconda2/lib/python2.7/site-packages/sklearn/utils/validation.py:386: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and willraise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "regr = regression(Y,X)\n",
    "test = all_val_dict['www.facebook.com'][0].values()\n",
    "test = np.array(ss.zscore(test)).T\n",
    "print regr.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
