{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn import datasets, linear_model\n",
    "from scipy import stats as ss\n",
    "\n",
    "file = [\"google.com\",\n",
    "    \"youtube.com\",\n",
    "    \"facebook.com\",\n",
    "    \"baidu.com\",\n",
    "    \"yahoo.com\",\n",
    "    \"wikipedia.org\",\n",
    "    \"amazon.com\",\n",
    "    \"qq.com\",\n",
    "    \"twitter.com\",\n",
    "    \"google.co.in\",\n",
    "    \"live.com\",\n",
    "    \"taobao.com\",\n",
    "    \"bing.com\",\n",
    "    \"google.co.jp\",\n",
    "    \"msn.com\",\n",
    "    \"yahoo.co.jp\",\n",
    "    \"sina.com.cn\",\n",
    "    \"linkedin.com\",\n",
    "    \"weibo.com\",\n",
    "    \"vk.com\",\n",
    "    \"instagram.com\",\n",
    "    \"google.ru\",\n",
    "    \"yandex.ru\",\n",
    "    \"hao123.com\",\n",
    "    \"google.de\",\n",
    "    \"ebay.com\",\n",
    "    \"reddit.com\",\n",
    "    \"google.co.uk\",\n",
    "    \"google.com.br\",\n",
    "    \"amazon.co.jp\",\n",
    "    \"t.co\",\n",
    "    \"google.fr\",\n",
    "    \"pinterest.com\",\n",
    "    \"mail.ru\",\n",
    "    \"tmall.com\",\n",
    "    \"360.cn\",\n",
    "    \"microsoft.com\",\n",
    "    \"netflix.com\",\n",
    "    \"onclickads.net\",\n",
    "    \"google.it\",\n",
    "    \"sohu.com\",\n",
    "    \"wordpress.com\",\n",
    "    \"tumblr.com\",\n",
    "    \"google.es\",\n",
    "    \"blogspot.com\",\n",
    "    \"imgur.com\",\n",
    "    \"naver.com\",\n",
    "    \"paypal.com\",\n",
    "    \"stackoverflow.com\",\n",
    "    \"chinadaily.com.cn\",\n",
    "    \"xvideos.com\",\n",
    "    \"apple.com\",\n",
    "    \"google.com.mx\",\n",
    "    \"aliexpress.com\",\n",
    "    \"gmw.cn\",\n",
    "    \"imdb.com\",\n",
    "    \"fc2.com\",\n",
    "    \"google.co.kr\",\n",
    "    \"diply.com\",\n",
    "    \"github.com\",\n",
    "    \"google.ca\",\n",
    "    \"pornhub.com\",\n",
    "    \"google.com.hk\",\n",
    "    \"amazon.de\",\n",
    "    \"office.com\",\n",
    "    \"ok.ru\",\n",
    "    \"whatsapp.com\",\n",
    "    \"google.com.tr\",\n",
    "    \"alibaba.com\",\n",
    "    \"rakuten.co.jp\",\n",
    "    \"jd.com\",\n",
    "    \"ask.com\",\n",
    "    \"google.co.id\",\n",
    "    \"kat.cr\",\n",
    "    \"nicovideo.jp\",\n",
    "    \"craigslist.org\",\n",
    "    \"google.pl\",\n",
    "    \"pixnet.net\",\n",
    "    \"xinhuanet.com\",\n",
    "    \"tianya.cn\",\n",
    "    \"soso.com\",\n",
    "    \"xhamster.com\",\n",
    "    \"blogger.com\",\n",
    "    \"googleusercontent.com\",\n",
    "    \"amazon.in\",\n",
    "    \"go.com\",\n",
    "    \"dropbox.com\",\n",
    "    \"google.com.au\",\n",
    "    \"cntv.cn\",\n",
    "    \"amazon.co.uk\",\n",
    "    \"bongacams.com\",\n",
    "    \"outbrain.com\",\n",
    "    \"youku.com\",\n",
    "    \"coccoc.com\",\n",
    "    \"wikia.com\",\n",
    "    \"microsoftonline.com\",\n",
    "    \"youth.cn\",\n",
    "    \"cnn.com\",\n",
    "    \"google.com.tw\",\n",
    "    \"163.com\"]\n",
    "\n",
    "category = {}\n",
    "category[\"www.google.com\"] = 0\n",
    "category[\"www.facebook.com\"] = 1\n",
    "category[\"www.youtube.com\"] = 2\n",
    "category[\"www.baidu.com\"] = 0\n",
    "category[\"www.yahoo.com\"] = 1\n",
    "category[\"www.amazon.com\"] = 2\n",
    "category[\"www.wikipedia.org\"] = 3\n",
    "category[\"www.twitter.com\"] = 1\n",
    "category[\"www.google.co.in\"] = 0\n",
    "category[\"www.linkedin.com\"] = 1\n",
    "category[\"www.yahoo.co.jp\"] = 1\n",
    "category[\"www.google.co.jp\"] = 0\n",
    "category[\"www.google.ca\"] = 0\n",
    "category[\"www.qq.com\"] = 2\n",
    "category[\"www.taobao.com\"] = 2\n",
    "category[\"www.live.com\"] = 1\n",
    "category[\"www.google.com.mx\"] = 0\n",
    "category[\"www.google.com.hk\"] = 0\n",
    "category[\"www.pornhub.com\"] = 2\n",
    "category[\"www.alibaba.com\"] = 2\n",
    "category[\"www.amazon.co.uk\"] = 2\n",
    "category[\"www.google.com.tr\"] = 0\n",
    "category[\"www.adobe.com\"] = 0\n",
    "category[\"www.gmail.com\"] = 0\n",
    "category[\"www.xhamster.com\"] = 2\n",
    "category[\"www.ebay.de\"] = 2\n",
    "category[\"www.google.pl\"] = 0\n",
    "category[\"www.google.com.au\"] = 0\n",
    "category[\"www.dailymotion.com\"] = 2\n",
    "category[\"www.bbc.co.uk\"] = 2\n",
    "category[\"www.google.co.id\"] = 0\n",
    "category[\"www.flipkart.com\"] = 2\n",
    "category[\"www.cnn.com\"] = 2\n",
    "category[\"www.booking.com\"] = 2\n",
    "category[\"www.github.com\"] = 0\n",
    "category[\"www.dropbox.com\"] = 0\n",
    "category[\"www.people.com.cn\"] = 2\n",
    "category[\"www.nicovideo.jp\"] = 2\n",
    "category[\"www.googleusercontent.com\"] = 0\n",
    "category[\"www.weibo.com\"] = 2\n",
    "category[\"www.sina.com.cn\"] = 2\n",
    "category[\"www.adcash.com\"] = 0\n",
    "category[\"www.ok.ru\"] = 2\n",
    "category[\"www.diply.com\"] = 2\n",
    "category[\"www.tianya.cn\"] = 2\n",
    "category[\"www.jd.com\"] = 2\n",
    "category[\"www.cntv.cn\"] = 0\n",
    "category[\"www.go.com\"] = 2\n",
    "category[\"www.naver.com\"] = 0\n",
    "category[\"www.kat.cr\"] = 0\n",
    "category[\"www.soso.com\"] = 0\n",
    "category[\"www.wikia.com\"] = 0\n",
    "category[\"www.163.com\"] = 2\n",
    "category[\"www.gmw.cn\"] = 2\n",
    "category[\"www.pixnet.net\"] = 3\n",
    "category[\"www.outbrain.com\"] = 3\n",
    "category[\"www.xinhuanet.com\"] = 2\n",
    "category[\"www.rakuten.co.jp\"] = 2\n",
    "category[\"www.detail.tmall.com\"] = 0\n",
    "category[\"www.chinadaily.com.cn\"] = 0\n",
    "\n",
    "def find_PLT(filename):\n",
    "    file = open(filename)\n",
    "    list = file.readlines()\n",
    "    mintime = 0\n",
    "    for line in list:\n",
    "        match = re.match('.*requestTime.: ([0-9^.]+)', line)\n",
    "        if match is not None:\n",
    "            mintime = float(match.groups(0)[0])\n",
    "            break\n",
    "    maxtime = 0\n",
    "    for line in list:\n",
    "        match = re.match('.*time.: ([0-9^.]+)',line)\n",
    "        if match is not None:\n",
    "            if float(match.groups(0)[0]) > maxtime:\n",
    "                maxtime = float(match.groups(0)[0])\n",
    "                \n",
    "    length = 0\n",
    "    for line in list:\n",
    "        match = re.match('.*\"len\": ([0-9]+), \"from',line)\n",
    "        if match is not None:\n",
    "            for val in match.groups(0):\n",
    "                length += int(val)                \n",
    "    \n",
    "    return (maxtime - mintime,mintime,maxtime,length)\n",
    "            \n",
    "def findcount(text, list):\n",
    "    feature = Counter()\n",
    "    for i in range(4):\n",
    "        feature[list[i]] = len(re.findall('\\.' + list[i],text))\n",
    "#         print list[i],\":\",feature[list[i]]\n",
    "    for i in range(4,len(list)):\n",
    "        feature[list[i]] = len(re.findall(list[i],text))\n",
    "    return feature\n",
    "\n",
    "\n",
    "def findAllPLT(name,count):\n",
    "    list = []\n",
    "    featureList = ['png','gif','css','js','Resource']\n",
    "    feature = Counter()\n",
    "    length = 0\n",
    "    for i in range(count):\n",
    "        filename = name + str(i)  + \".txt\"\n",
    "        text = open(filename).read()\n",
    "        feature += findcount(text,featureList)\n",
    "        (time,min,max,length) = find_PLT(filename)\n",
    "        list.append(time)\n",
    "    \n",
    "    for key in featureList:\n",
    "        if key in feature:\n",
    "            feature[key] = (feature[key]*1.0)/count\n",
    "        else:\n",
    "            feature[key] = 0\n",
    "    feature['length'] = length\n",
    "    return feature,list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filepath = \"/Users/Aman/Desktop/Colin/data_all/new_logs/\"\n",
    "def all_file():\n",
    "    dictionary = {}\n",
    "    for website in file:\n",
    "        feature,list = findAllPLT(filepath + website,10)\n",
    "        dictionary[website] = (feature,list)\n",
    "    return dictionary\n",
    "\n",
    "all_val_dict = all_file()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Coefficients: \\n', array([ 0.30561588,  0.13275116, -0.04940217,  0.31840384, -0.01278579,\n",
      "       -0.183342  ]))\n",
      "Residual sum of squares: 0.66\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'www.yahoo.com'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-019083f8ca55>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mregr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mregression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_val_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'www.yahoo.com'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;31m# test = test[1:-1]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'www.yahoo.com'"
     ]
    }
   ],
   "source": [
    "def regression(Y,X):\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    Y = np.array(ss.zscore(Y)).T\n",
    "#     X = np.array([x + 0.1001 for x in X])\n",
    "    X = np.array([(ss.zscore(x)) for x in X.T]).T\n",
    "    \n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(X,Y)\n",
    "    print('Coefficients: \\n', regr.coef_)\n",
    "    print(\"Residual sum of squares: %.2f\"% np.mean((regr.predict(X) - Y) ** 2))\n",
    "    \n",
    "    return regr    \n",
    "\n",
    "def getValueRegr(all_val_dict):\n",
    "    Y = []\n",
    "    X = []\n",
    "    for website in file:\n",
    "        if np.sum(all_val_dict[website][1]) == 0:\n",
    "            continue\n",
    "        Y.append(np.mean(all_val_dict[website][1][4]))\n",
    "        x1 = all_val_dict[website][0].values()\n",
    "        \n",
    "        X.append(x1)\n",
    "    \n",
    "    return (Y,X)\n",
    "\n",
    "Y,X = getValueRegr(all_val_dict)\n",
    "\n",
    "regr = regression(Y,X)\n",
    "test = all_val_dict['www.yahoo.com'][0].values()\n",
    "print test\n",
    "# test = test[1:-1]\n",
    "test = np.array(ss.zscore(test)).T\n",
    "print test\n",
    "print regr.predict(test)\n",
    "\n",
    "\n",
    "for website in file:\n",
    "    test = all_val_dict[website][0].values()\n",
    "    test = np.array(ss.zscore(test)).T\n",
    "    print regr.predict(test)\n",
    "    print all_val_dict[website][1][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "def pageloaditeration():    \n",
    "    for website in file:\n",
    "        if website in all_val_dict.keys():\n",
    "            if max(all_val_dict[website][1]) < 8 and min(all_val_dict[website][1])  > 0:\n",
    "#                 all_val_dict[website][1].sort()\n",
    "#                 all_val_dict[website][1].reverse()\n",
    "                plt.plot(all_val_dict[website][1],linewidth=2.0)\n",
    "\n",
    "    plt.ylabel('Time in seconds ---->')\n",
    "    plt.xlabel('Iterations ---->')\n",
    "    plt.ylim(ymax=8)\n",
    "    plt.xlim(xmax=7)\n",
    "    plt.grid(True)\n",
    "    plt.title(\"PAGELOAD TIME  vs  ITERATION\")\n",
    "    plt.show()\n",
    "\n",
    "def scatterplot(file):\n",
    "    for website in file:\n",
    "       plt.scatter(sum(all_val_dict[website][0].values()),np.mean(all_val_dict[website][1]),alpha=0.5,color=\"blue\")\n",
    "\n",
    "    plt.ylabel('Time in seconds ---->')\n",
    "    plt.xlabel('Number of objects ---->')\n",
    "    plt.grid(True)\n",
    "    plt.title(\"PAGELOAD TIME  vs  #OBJECTS\")\n",
    "    plt.show()\n",
    "\n",
    "def pageloadvsobj(all_val_dict):\n",
    "    for website in file:\n",
    "        sum = 0.0\n",
    "        i = 0\n",
    "        for key in all_val_dict[website][0]:\n",
    "            sum += regr.coef_[i]* all_val_dict[website][0][key]\n",
    "            i += 1\n",
    "            sum = max(sum,2)\n",
    "            plt.scatter(sum,np.mean(all_val_dict[website][1]),alpha=0.5)\n",
    "    \n",
    "    plt.ylabel('Time in seconds ---->')\n",
    "    plt.xlabel('Number of objects ---->')\n",
    "    plt.grid(True)\n",
    "    plt.xlim(xmin=-5)\n",
    "    plt.ylim(ymin=0)\n",
    "    plt.title(\"PAGELOAD TIME  vs  #OBJECTS\")\n",
    "    plt.show()\n",
    "\n",
    "def sp():\n",
    "    fig = plt.figure()\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    x = []\n",
    "    y = []\n",
    "    z = []\n",
    "    yaxis = []\n",
    "    keys = ['png','gif','css','js']\n",
    "    for website in file:\n",
    "        sum = 0\n",
    "        for v in keys:\n",
    "            sum += all_val_dict[website][0][v]\n",
    "        x.append(sum)\n",
    "        y.append(all_val_dict[website][0][\"length\"])\n",
    "        z.append(all_val_dict[website][0][\"Resource\"])\n",
    "        yaxis.append(np.mean(all_val_dict[website][1]))\n",
    "    \n",
    "    x = np.array(ss.zscore(x))\n",
    "    y = np.array(ss.zscore(y))\n",
    "    z = np.array(ss.zscore(z))\n",
    "   \n",
    "    colors = iter(cm.rainbow(np.linspace(0, 1, 3)))\n",
    "\n",
    "    ax1.scatter(x,yaxis , s=35,color=next(colors), marker=\"o\",edgecolor = 'black', label='#Objects')\n",
    "    ax1.scatter(y,yaxis , s=35,color=next(colors), marker=\"s\",edgecolor = 'black', label='LengthWebsite')\n",
    "    ax1.scatter(z,yaxis , s=35,color=next(colors), marker=\"p\",edgecolor = 'black', label='#Resources Contacted')\n",
    "    plt.legend(loc='upper left');\n",
    "    plt.colors()\n",
    "    plt.ylabel('Time in seconds ---->')\n",
    "    plt.xlabel('Features(NORMALIZED TO FIT/COMPARE) ---->')\n",
    "    plt.grid(True)\n",
    "    plt.title(\"PAGELOAD TIME vs Features\")\n",
    "    plt.show()\n",
    "\n",
    "pageloaditeration()\n",
    "pageloadvsobj(all_val_dict)\n",
    "scatterplot(file)\n",
    "sp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "filepath = '/Users/Aman/Desktop/Colin/'\n",
    "df = pd.read_csv(filepath + 'website_metrics.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = df['median_page_download_time']\n",
    "X = df[['number_of_servers_contacted',\n",
    "        'number_of_object_requests_median',\n",
    "        'object_request_size_median',\n",
    "        'number_of_javascript_objects_median',\n",
    "       'number_of_javascript_objects_median',\n",
    "       'size_of_javascript_objects_median',\n",
    "       'number_of_image_objects_median',\n",
    "       'size_of_image_objects_median',\n",
    "       'number_of_flash_objects_median',\n",
    "       'size_of_flash_objects_median',\n",
    "       'number_of_css_objects_median',\n",
    "       'size_of_css_objects_median',\n",
    "       ]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
